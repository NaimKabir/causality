{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant simulation\n",
    "\n",
    "First we'll create *n* participants in our experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of these participants, we'll randomly assign them some (Compliance, Response) behavior combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "compliance_partitions = ['always_taker', \n",
    "                         'complier', \n",
    "                         'defier', \n",
    "                         'never_taker']\n",
    "response_partitions = ['always_better', \n",
    "                       'helped', \n",
    "                       'hurt', \n",
    "                       'never_better']\n",
    "\n",
    "# Take the cross product of these sets of types\n",
    "\n",
    "partition_types = product(compliance_partitions, response_partitions)\n",
    "partition_types = np.array(list(partition_types))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll simulate probabilities that our participants \n",
    "# will belong to one of the 16 possible behavior combinations\n",
    "\n",
    "random_floats = np.random.random([1,16]) \n",
    "partition_probabilities = normalize(random_floats, 'l1')\n",
    "partition_probabilities = partition_probabilities.flatten()\n",
    "\n",
    "# to be a true set of probabilities, the vector sum \n",
    "# needs to be 1\n",
    "\n",
    "# sometimes this can fail because of precision errors, \n",
    "# so let's assert it\n",
    "\n",
    "assert partition_probabilities.sum() == 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing participant compliance and response behaviors according to the\n",
    "# specified distribution\n",
    "\n",
    "participant_partition = np.random.choice(\n",
    "                            range(len(partition_types)), \n",
    "                            n, \n",
    "                            p=partition_probabilities\n",
    "                        )\n",
    "\n",
    "compliance_type, response_type = list(zip(*partition_types[participant_partition]))\n",
    "\n",
    "# assigning participants to Control and Treatment groups \n",
    "# with 50% probability\n",
    "\n",
    "assignments = ['control', 'treatment']\n",
    "participant_assignment = np.random.choice(assignments, n)\n",
    "\n",
    "# compiling all information into our dataframe\n",
    "\n",
    "df = pd.DataFrame({'assignment': participant_assignment,\n",
    "                   'compliance_type': compliance_type,\n",
    "                   'response_type': response_type})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate whether participants took treatment\n",
    "\n",
    "Depending on assignment and compliance type, we can simulate whether or not each participant took the treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the participant is an always_taker, \n",
    "# they'll always take the treatment.\n",
    "\n",
    "df['took_treatment'] = (df.compliance_type == 'always_taker')\n",
    "\n",
    "# if they're a complier, they'll take the treatment \n",
    "# as long as they're in the treatment condition.\n",
    "\n",
    "df['took_treatment'] = df['took_treatment'] \\\n",
    "                        | ( \n",
    "                            (df.compliance_type == 'complier') \n",
    "                            & \n",
    "                            (df.assignment == 'treatment') \n",
    "                          )\n",
    "\n",
    "# if they're a defier, they'll only take the treatment \n",
    "# if they were in the control condition.\n",
    "\n",
    "df['took_treatment'] = df['took_treatment'] \\\n",
    "                        | ( \n",
    "                            (df.compliance_type == 'defier') \n",
    "                            & \n",
    "                            (df.assignment == 'control') \n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Outcomes\n",
    "\n",
    "Now we can simulate outcomes from the experiment.\n",
    "\n",
    "Depending on whether they took the treatment and their `response_type`, did they end up in a Good or Bad state after the experiment's conclusion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the participant is of the always_better type, \n",
    "# they'll definitely have a good outcome.\n",
    "\n",
    "df['good_outcome'] = (df.response_type == 'always_better') \n",
    "\n",
    "# if the participant is of the 'helped' type, \n",
    "# they'll have a good outcome as long as they\n",
    "# took treatment.\n",
    "\n",
    "df['good_outcome'] = df['good_outcome'] \\\n",
    "                     | ( \n",
    "                        (df.response_type == 'helped') \n",
    "                        & \n",
    "                        (df.took_treatment) \n",
    "                       )\n",
    "\n",
    "# Otherwise, the outcome is going to be bad\n",
    "# and the column will have a False value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can observe the probabilities of each \n",
    "# (Treatment, Outcome) combination\n",
    "# that would emerge, given the assignment\n",
    "\n",
    "df['n'] = 1\n",
    "results = df.groupby(['assignment', \n",
    "                      'took_treatment', \n",
    "                      'good_outcome']).count().n\n",
    "results = results.to_frame()\n",
    "results['assignment_n'] = results.groupby('assignment').transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P( X, Y | Z )</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>assignment</th>\n",
       "      <th>took_treatment</th>\n",
       "      <th>good_outcome</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">control</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>0.362173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.144869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>0.259557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.233400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">treatment</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>False</th>\n",
       "      <td>0.411531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.141153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">True</th>\n",
       "      <th>False</th>\n",
       "      <td>0.190855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>0.256461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        P( X, Y | Z )\n",
       "assignment took_treatment good_outcome               \n",
       "control    False          False              0.362173\n",
       "                          True               0.144869\n",
       "           True           False              0.259557\n",
       "                          True               0.233400\n",
       "treatment  False          False              0.411531\n",
       "                          True               0.141153\n",
       "           True           False              0.190855\n",
       "                          True               0.256461"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_states = results.n / results.assignment_n\n",
    "p_states = p_states.rename(\"P( X, Y | Z )\")\n",
    "\n",
    "# display\n",
    "\n",
    "p_states.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intent-to-treat average treatment effect\n",
    "\n",
    "# sum up all 'good' from the Treatment column, and subtract by all 'good' from the Control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE: 0.0193\n"
     ]
    }
   ],
   "source": [
    "# Intent to treat analysis:\n",
    "\n",
    "itt_ate = df[df.assignment == 'treatment'].good_outcome.mean() \\\n",
    "          - df[df.assignment == 'control'].good_outcome.mean() \n",
    "\n",
    "print(\"ATE: %6.4f\" % itt_ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causal analysis\n",
    "\n",
    "# get all the probabilities we need: p(z,x,y) for each z,x,y combination\n",
    "states = list(product(['treatment','control'],[0,1], [0,1]))\n",
    "\n",
    "p_states = {f\"{assignment}/{'treated' if took == 1 else 'untreated'}/{'good' if outcome ==1 else 'bad'}\" : \n",
    "                ( (df[df.assignment == assignment].took_treatment == took)\n",
    "                   & (df[df.assignment == assignment].good_outcome == outcome)  ).mean()\n",
    "                for assignment, took, outcome in states\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'treatment/untreated/bad': 0.4115308151093439,\n",
       " 'treatment/untreated/good': 0.1411530815109344,\n",
       " 'treatment/treated/bad': 0.1908548707753479,\n",
       " 'treatment/treated/good': 0.25646123260437376,\n",
       " 'control/untreated/bad': 0.36217303822937624,\n",
       " 'control/untreated/good': 0.1448692152917505,\n",
       " 'control/treated/bad': 0.2595573440643863,\n",
       " 'control/treated/good': 0.23340040241448692}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16300000000000003"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_ate = (df.response_type == 'helped').mean() - (df.response_type == 'hurt').mean()\n",
    "true_ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear programming problem\n",
    "import pulp\n",
    "min_problem = pulp.LpProblem(\"min ATE\", pulp.LpMinimize)\n",
    "max_problem = pulp.LpProblem(\"max ATE\", pulp.LpMaximize)\n",
    "\n",
    "# our hidden variables are the the probability of being in one of the partitions\n",
    "partition_names = ['/'.join([compliance, response]) for compliance, response in partition_types]\n",
    "q = {partition: pulp.LpVariable(partition, lowBound=0) for partition in partition_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since our hidden vars are probabilities the sum of them should all be under 1\n",
    "min_problem += sum([v for k,v in q.items()]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statements\n",
    "p_treatment_untreated_bad = q['never_taker/never_better'] + q['defier/never_better'] \\\n",
    "                             + q['never_taker/helped'] + q['defier/helped']\n",
    "\n",
    "p_treatment_untreated_good = q['never_taker/always_better'] + q['defier/always_better'] \\\n",
    "                             + q['never_taker/hurt'] + q['defier/hurt']\n",
    "\n",
    "p_treatment_treated_bad = q['always_taker/never_better'] + q['complier/never_better'] \\\n",
    "                             + q['always_taker/hurt'] + q['complier/hurt']\n",
    "\n",
    "p_treatment_treated_good = q['always_taker/always_better'] + q['complier/always_better'] \\\n",
    "                             + q['always_taker/helped'] + q['complier/helped']\n",
    "\n",
    "p_control_untreated_bad = q['never_taker/never_better'] + q['complier/never_better'] \\\n",
    "                             + q['never_taker/helped'] + q['complier/helped']\n",
    "\n",
    "p_control_untreated_good = q['never_taker/always_better'] + q['complier/never_better'] \\\n",
    "                             + q['never_taker/hurt'] + q['complier/hurt']\n",
    "\n",
    "p_control_treated_bad = q['always_taker/never_better'] + q['defier/never_better'] \\\n",
    "                             + q['always_taker/hurt'] + q['defier/hurt']\n",
    "\n",
    "p_control_treated_good = q['always_taker/always_better'] + q['defier/always_better'] \\\n",
    "                             + q['always_taker/helped'] + q['defier/helped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a natural mapping from probabilities we see to the hidden variables we have\n",
    "# we'll spell these out one by one.\n",
    "# there are probably smarter ways to express this as a vector operation,\n",
    "# but this is easier to understand\n",
    "min_problem += p_treatment_untreated_bad == p_states['treatment/untreated/bad']\n",
    "\n",
    "min_problem += p_treatment_untreated_good == p_states['treatment/untreated/good']\n",
    "\n",
    "min_problem += p_treatment_treated_bad == p_states['treatment/treated/bad']\n",
    "\n",
    "min_problem += p_control_untreated_bad == p_states['control/untreated/bad']\n",
    "\n",
    "min_problem += p_control_untreated_good == p_states['control/untreated/good']\n",
    "\n",
    "min_problem += p_control_treated_bad == p_states['control/treated/bad']\n",
    "\n",
    "#min_problem += p_treatment_treated_good == p_states['treatment/treated/good']\n",
    "\n",
    "#min_problem += p_control_treated_good == p_states['control/treated/good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_problem += q['complier/helped'] + q['defier/helped'] + q['always_taker/helped'] + q['never_taker/helped'] \\\n",
    "              - q['complier/hurt'] - q['defier/hurt'] - q['always_taker/hurt'] - q['never_taker/hurt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Optimal'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pulp.LpStatus[min_problem.solve()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'always_taker/always_better': 0.23711654,\n",
       " 'always_taker/helped': 0.0,\n",
       " 'always_taker/hurt': 0.18713874,\n",
       " 'always_taker/never_better': 0.0,\n",
       " 'complier/always_better': 0.0,\n",
       " 'complier/helped': 0.019344696,\n",
       " 'complier/hurt': 0.0,\n",
       " 'complier/never_better': 0.0037161338,\n",
       " 'defier/always_better': 0.0,\n",
       " 'defier/helped': 0.0,\n",
       " 'defier/hurt': 0.0,\n",
       " 'defier/never_better': 0.072418607,\n",
       " 'never_taker/always_better': 0.0,\n",
       " 'never_taker/helped': 0.0,\n",
       " 'never_taker/hurt': 0.14115308,\n",
       " 'never_taker/never_better': 0.33911221}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_min = {partition:pulp.value(partition_p) for partition, partition_p in q.items()}\n",
    "q_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_constraints(problem):\n",
    "    \n",
    "    # our hidden variables are the the probability of being in one of the partitions\n",
    "    partition_names = ['/'.join([compliance, response]) for compliance, response in partition_types]\n",
    "    q = {partition: pulp.LpVariable(partition, lowBound=0) for partition in partition_names}\n",
    "    \n",
    "    problem += sum([v for k,v in q.items()]) == 1\n",
    "    \n",
    "    p_treatment_untreated_bad = q['never_taker/never_better'] + q['defier/never_better'] \\\n",
    "                             + q['never_taker/helped'] + q['defier/helped']\n",
    "\n",
    "    p_treatment_untreated_good = q['never_taker/always_better'] + q['defier/always_better'] \\\n",
    "                                 + q['never_taker/hurt'] + q['defier/hurt']\n",
    "\n",
    "    p_treatment_treated_bad = q['always_taker/never_better'] + q['complier/never_better'] \\\n",
    "                                 + q['always_taker/hurt'] + q['complier/hurt']\n",
    "\n",
    "    p_treatment_treated_good = q['always_taker/always_better'] + q['complier/always_better'] \\\n",
    "                                 + q['always_taker/helped'] + q['complier/helped']\n",
    "\n",
    "    p_control_untreated_bad = q['never_taker/never_better'] + q['complier/never_better'] \\\n",
    "                                 + q['never_taker/helped'] + q['complier/helped']\n",
    "\n",
    "    p_control_untreated_good = q['never_taker/always_better'] + q['complier/never_better'] \\\n",
    "                                 + q['never_taker/hurt'] + q['complier/hurt']\n",
    "\n",
    "    p_control_treated_bad = q['always_taker/never_better'] + q['defier/never_better'] \\\n",
    "                                 + q['always_taker/hurt'] + q['defier/hurt']\n",
    "\n",
    "    p_control_treated_good = q['always_taker/always_better'] + q['defier/always_better'] \\\n",
    "                                 + q['always_taker/helped'] + q['defier/helped']\n",
    "    \n",
    "    problem += p_treatment_untreated_bad == p_states['treatment/untreated/bad']\n",
    "    problem += p_treatment_untreated_good == p_states['treatment/untreated/good']\n",
    "    problem += p_treatment_treated_bad == p_states['treatment/treated/bad']\n",
    "    problem += p_control_untreated_bad == p_states['control/untreated/bad']\n",
    "    problem += p_control_untreated_good == p_states['control/untreated/good']\n",
    "    problem += p_control_treated_bad == p_states['control/treated/bad']\n",
    "    \n",
    "    problem += q['complier/helped'] + q['defier/helped'] + q['always_taker/helped'] + q['never_taker/helped'] \\\n",
    "              - q['complier/hurt'] - q['defier/hurt'] - q['always_taker/hurt'] - q['never_taker/hurt']\n",
    "    \n",
    "    \n",
    "    status = pulp.LpStatus[problem.solve()]\n",
    "    \n",
    "    if status != 'Optimal':\n",
    "        raise ValueError('Infeasible')\n",
    "        \n",
    "    q_solved = {partition:pulp.value(partition_p) for partition, partition_p in q.items()}\n",
    "    \n",
    "    return q_solved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "PulpSolverError",
     "evalue": "Pulp: Error while executing /usr/local/lib/python3.6/site-packages/pulp/solverdir/cbc/osx/64/cbc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPulpSolverError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e6469ee20d34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mq_min\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_problem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mq_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_constraints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_problem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5f230a29f6d0>\u001b[0m in \u001b[0;36mapply_constraints\u001b[0;34m(problem)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpulp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLpStatus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mproblem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'Optimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pulp/pulp.py\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, solver, **kwargs)\u001b[0m\n\u001b[1;32m   1669\u001b[0m         \u001b[0;31m#time it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutionTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1671\u001b[0;31m         \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactualSolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolutionTime\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestoreObjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwasNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdummyVar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pulp/solvers.py\u001b[0m in \u001b[0;36mactualSolve\u001b[0;34m(self, lp, **kwargs)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactualSolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;34m\"\"\"Solve a well formulated lp problem\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_CBC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mavailable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pulp/solvers.py\u001b[0m in \u001b[0;36msolve_CBC\u001b[0;34m(self, lp, use_mps)\u001b[0m\n\u001b[1;32m   1425\u001b[0m                                     self.path)\n\u001b[1;32m   1426\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmpSol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPulpSolverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pulp: Error while executing \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m             lp.status, values, reducedCosts, shadowPrices, slacks = self.readsol_MPS(\n",
      "\u001b[0;31mPulpSolverError\u001b[0m: Pulp: Error while executing /usr/local/lib/python3.6/site-packages/pulp/solverdir/cbc/osx/64/cbc"
     ]
    }
   ],
   "source": [
    "q_min = apply_constraints(min_problem)\n",
    "q_max = apply_constraints(max_problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ate = lambda q: q['complier/helped'] + q['defier/helped'] + q['always_taker/helped'] + q['never_taker/helped'] \\\n",
    "              - q['complier/hurt'] - q['defier/hurt'] - q['always_taker/hurt'] - q['never_taker/hurt']\n",
    "\n",
    "min_ate = ate(q_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'q_max' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4aba0e024c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_ate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'q_max' is not defined"
     ]
    }
   ],
   "source": [
    "max_ate = ate(q_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
