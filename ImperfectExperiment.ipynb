{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import pulp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baking off intent-to-treat vs. analysis of compliance\n",
    "n = 5000\n",
    "\n",
    "compliance_partitions = ['always_taker', 'complier', 'defier', 'never_taker']\n",
    "response_partitions = ['always_better', 'helped', 'hurt', 'never_better']\n",
    "partition_types = np.array(list(product(compliance_partitions, response_partitions)))\n",
    "\n",
    "partition_probabilities = np.random.random(16)\n",
    "partition_probabilities = partition_probabilities / partition_probabilities.sum()\n",
    "\n",
    "assert partition_probabilities.sum() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Participant simulation\n",
    "\n",
    "# drawing participant compliance and response behaviors according to the\n",
    "# specified distribution\n",
    "participant_partition = np.random.choice(range(len(partition_types)), n, p=partition_probabilities)\n",
    "compliance_type, response_type = list(zip(*partition_types[participant_partition]))\n",
    "\n",
    "# randomly assigning participants to Control and Treatment groups\n",
    "assignments = np.array(['control', 'treatment'])\n",
    "participant_assignment = assignments[np.random.randint(0, 2, n)]\n",
    "\n",
    "# compiling all information into our dataframe\n",
    "df = pd.DataFrame({'assignment': participant_assignment,\n",
    "                   'compliance_type': compliance_type,\n",
    "                   'response_type': response_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate outcomes\n",
    "\n",
    "# Depending on assignment and compliance type, do you take the treatment?\n",
    "df['took_treatment'] = (df.compliance_type == 'always_taker') \\\n",
    "                       | ( (df.compliance_type == 'complier') & (df.assignment == 'treatment')) \\\n",
    "                       | ( (df.compliance_type == 'defier') & (df.assignment == 'control'))\n",
    "\n",
    "df.took_treatment = df.took_treatment.astype('int32')\n",
    "\n",
    "# Depending on whether you took the treatment and your response_type, what happens to you?\n",
    "df['good_outcome'] = (df.response_type == 'always_better') \\\n",
    "                     | ( (df.response_type == 'helped') & (df.took_treatment) )\n",
    "\n",
    "df.good_outcome = df.good_outcome.astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44166666666666665\n",
      "0.4717741935483871\n",
      "ATE: -0.0301\n"
     ]
    }
   ],
   "source": [
    "# Intent to treat analysis:\n",
    "\n",
    "print(df[df.assignment == 'treatment'].good_outcome.mean())\n",
    "print(df[df.assignment == 'control'].good_outcome.mean())\n",
    "\n",
    "itt_ate = df[df.assignment == 'treatment'].good_outcome.mean() \\\n",
    "- df[df.assignment == 'control'].good_outcome.mean() \n",
    "\n",
    "print(\"ATE: %6.4f\" % itt_ate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Causal analysis\n",
    "\n",
    "# get all the probabilities we need: p(z,x,y) for each z,x,y combination\n",
    "states = list(product(['treatment','control'],[0,1], [0,1]))\n",
    "\n",
    "p_states = {f\"{assignment}/{'treated' if took == 1 else 'untreated'}/{'good' if outcome ==1 else 'bad'}\" : \n",
    "            ((df.assignment == assignment) \n",
    "               & (df.took_treatment == took) \n",
    "               & (df.good_outcome == outcome)).mean()\n",
    "            for assignment, took, outcome in states\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'treatment/untreated/bad': 0.196,\n",
       " 'treatment/untreated/good': 0.0452,\n",
       " 'treatment/treated/bad': 0.0854,\n",
       " 'treatment/treated/good': 0.1774,\n",
       " 'control/untreated/bad': 0.1732,\n",
       " 'control/untreated/good': 0.0518,\n",
       " 'control/treated/bad': 0.0888,\n",
       " 'control/treated/good': 0.1822}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ate = (df.response_type == 'helped').mean() - (df.response_type == 'hurt').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear programming problem\n",
    "\n",
    "min_problem = pulp.LpProblem(\"min ATE\", pulp.LpMinimize)\n",
    "max_problem = pulp.LpProblem(\"max ATE\", pulp.LpMaximize)\n",
    "\n",
    "# our hidden variables are the the probability of being in one of the partitions\n",
    "partition_names = ['/'.join([compliance, response]) for compliance, response in partition_types]\n",
    "q = {partition: pulp.LpVariable(partition, 0, 1) for partition in partition_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since our hidden vars are probabilities the sum of them should all be under 1\n",
    "min_problem += sum([v for k,v in q.items()]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there's a natural mapping from probabilities we see to the hidden variables we have\n",
    "# we'll spell these out one by one.\n",
    "# there are probably smarter ways to express this as a vector operation,\n",
    "# but this is easier to understand\n",
    "min_problem += q['never_taker/never_better'] + q['defier/never_better'] \\\n",
    "             + q['never_taker/helped'] + q['defier/helped'] == p_states['treatment/untreated/bad']\n",
    "\n",
    "min_problem += q['never_taker/always_better'] + q['defier/always_better'] \\\n",
    "             + q['never_taker/hurt'] + q['defier/hurt'] == p_states['treatment/untreated/good']\n",
    "\n",
    "min_problem += q['always_taker/never_better'] + q['complier/never_better'] \\\n",
    "             + q['always_taker/hurt'] + q['complier/hurt'] == p_states['treatment/treated/bad']\n",
    "\n",
    "min_problem += q['always_taker/always_better'] + q['complier/always_better'] \\\n",
    "             + q['always_taker/helped'] + q['complier/helped'] == p_states['treatment/treated/good']\n",
    "\n",
    "min_problem += q['never_taker/never_better'] + q['complier/never_better'] \\\n",
    "             + q['never_taker/helped'] + q['complier/helped'] == p_states['control/untreated/bad']\n",
    "\n",
    "min_problem += q['never_taker/always_better'] + q['complier/never_better'] \\\n",
    "             + q['never_taker/hurt'] + q['complier/hurt'] == p_states['control/untreated/good']\n",
    "\n",
    "min_problem += q['always_taker/never_better'] + q['defier/never_better'] \\\n",
    "             + q['always_taker/hurt'] + q['defier/hurt'] == p_states['control/treated/bad']\n",
    "\n",
    "min_problem += q['always_taker/always_better'] + q['defier/always_better'] \\\n",
    "             + q['always_taker/helped'] + q['defier/helped'] == p_states['control/treated/good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/pulp/pulp.py:1349: UserWarning: Overwriting previously set objective.\n",
      "  warnings.warn(\"Overwriting previously set objective.\")\n"
     ]
    }
   ],
   "source": [
    "min_problem += q['complier/helped'] + q['defier/helped'] + q['always_taker/helped'] + q['never_taker/helped'] \\\n",
    "              - q['complier/hurt'] - q['defier/hurt'] - q['always_taker/hurt'] - q['never_taker/hurt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "min ATE:\n",
       "MINIMIZE\n",
       "1*always_taker_helped + -1*always_taker_hurt + 1*complier_helped + -1*complier_hurt + 1*defier_helped + -1*defier_hurt + 1*never_taker_helped + -1*never_taker_hurt + 0\n",
       "SUBJECT TO\n",
       "_C1: always_taker_always_better + always_taker_helped + always_taker_hurt\n",
       " + always_taker_never_better + complier_always_better + complier_helped\n",
       " + complier_hurt + complier_never_better + defier_always_better\n",
       " + defier_helped + defier_hurt + defier_never_better\n",
       " + never_taker_always_better + never_taker_helped + never_taker_hurt\n",
       " + never_taker_never_better = 1\n",
       "\n",
       "_C2: defier_helped + defier_never_better + never_taker_helped\n",
       " + never_taker_never_better = 0.196\n",
       "\n",
       "_C3: defier_always_better + defier_hurt + never_taker_always_better\n",
       " + never_taker_hurt = 0.0452\n",
       "\n",
       "_C4: always_taker_hurt + always_taker_never_better + complier_hurt\n",
       " + complier_never_better = 0.0854\n",
       "\n",
       "_C5: always_taker_always_better + always_taker_helped + complier_always_better\n",
       " + complier_helped = 0.1774\n",
       "\n",
       "_C6: complier_helped + complier_never_better + never_taker_helped\n",
       " + never_taker_never_better = 0.1732\n",
       "\n",
       "_C7: complier_hurt + complier_never_better + never_taker_always_better\n",
       " + never_taker_hurt = 0.0518\n",
       "\n",
       "_C8: always_taker_hurt + always_taker_never_better + defier_hurt\n",
       " + defier_never_better = 0.0888\n",
       "\n",
       "_C9: always_taker_always_better + always_taker_helped + defier_always_better\n",
       " + defier_helped = 0.1822\n",
       "\n",
       "VARIABLES\n",
       "always_taker_always_better <= 1 Continuous\n",
       "always_taker_helped <= 1 Continuous\n",
       "always_taker_hurt <= 1 Continuous\n",
       "always_taker_never_better <= 1 Continuous\n",
       "complier_always_better <= 1 Continuous\n",
       "complier_helped <= 1 Continuous\n",
       "complier_hurt <= 1 Continuous\n",
       "complier_never_better <= 1 Continuous\n",
       "defier_always_better <= 1 Continuous\n",
       "defier_helped <= 1 Continuous\n",
       "defier_hurt <= 1 Continuous\n",
       "defier_never_better <= 1 Continuous\n",
       "never_taker_always_better <= 1 Continuous\n",
       "never_taker_helped <= 1 Continuous\n",
       "never_taker_hurt <= 1 Continuous\n",
       "never_taker_never_better <= 1 Continuous"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
